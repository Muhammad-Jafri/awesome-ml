{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "- the input dims are (256,256,3)\n",
    "\n",
    "Dimension change during conv\n",
    "\n",
    "```\n",
    "n_out = (n_in + 2p - k)//s + 1\n",
    "```\n",
    "\n",
    "Some libraries accept [C, W, H] like pytorch however some want channel at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.image import imread\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATASET_BASE_DIR = \"./archive/pizza_not_pizza\"\n",
    "folder_name_label = {\"not_pizza\": 0, \"pizza\": 1}\n",
    "BATCH_SIZE = 32\n",
    "MODEL_PATH = \"./classifier.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms\n",
    "transform_pipeline = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize images to 256x256\n",
    "    transforms.ToTensor()  # Convert to tensor\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1966 images.\n",
      "1966\n",
      "Images shape: (1966, 3, 256, 256)\n",
      "Labels shape: (1966,)\n"
     ]
    }
   ],
   "source": [
    "class TrainingData:\n",
    "    def __init__(self, base_dir, folder_label_map):\n",
    "        \"\"\"\n",
    "        Initializes the TrainingData object.\n",
    "\n",
    "        Args:\n",
    "            base_dir (str): Path to the dataset base directory.\n",
    "            folder_label_map (dict): Mapping of folder names to labels.\n",
    "        \"\"\"\n",
    "        self.base_dir = base_dir\n",
    "        self.folder_label_map = folder_label_map\n",
    "        self.data = []  # To store (image, label) pairs\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Loads images and labels from the dataset directory.\n",
    "        \"\"\"\n",
    "        for folder_name, label in self.folder_label_map.items():\n",
    "            folder_path = os.path.join(self.base_dir, folder_name)\n",
    "            if not os.path.exists(folder_path):\n",
    "                print(f\"Warning: Folder {folder_path} does not exist.\")\n",
    "                continue\n",
    "\n",
    "            for filename in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                if file_path.endswith((\".png\", \".jpg\", \".jpeg\")):  # Valid image formats\n",
    "                    try:\n",
    "                        image = Image.open(file_path)  # Read the image\n",
    "                        image = transform_pipeline(image)\n",
    "\n",
    "                        \n",
    "                        self.data.append((image, label))  # Append (image, label) pair\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading {file_path}: {e}\")\n",
    "\n",
    "        print(f\"Loaded {len(self.data)} images.\")\n",
    "\n",
    "    def get_data(self):\n",
    "        \"\"\"\n",
    "        Returns the loaded data as separate arrays for images and labels.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (images, labels) where images is a NumPy array of all images and labels is a NumPy array of labels.\n",
    "        \"\"\"\n",
    "\n",
    "        print(len(self.data))\n",
    "        images, labels = zip(*self.data)  # Unzipping into separate lists\n",
    "        return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "# Usage\n",
    "training_data = TrainingData(DATASET_BASE_DIR, folder_name_label)\n",
    "training_data.load_data()\n",
    "\n",
    "# Retrieve images and labels\n",
    "images, labels = training_data.get_data()\n",
    "print(f\"Images shape: {images.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the split\n",
    "X_train, X_test,y_train, y_test = train_test_split(images, labels, random_state=104, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Render a sample\n",
    "# idx = 100\n",
    "# print(X_train[idx].shape)\n",
    "# plt.imshow(X_train[idx])\n",
    "# plt.axis(\"off\")\n",
    "# print(y_train[idx])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, learning_rate=0.001):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv_layers = nn.Sequential( # TODO relearn the dim calculations\n",
    "            # First conv block\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1), # Output (256,256,32)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # Output (128,128,32)\n",
    "            \n",
    "            # Second conv block\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1), # Output (128,128,64)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # Output (64,64,64)\n",
    "            \n",
    "            # Third conv block\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1), # Output (64,64,128)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # Output (32,32,128)\n",
    "        )\n",
    "        \n",
    "        # Calculate the size of flattened features\n",
    "        # After 3 max pooling layers with stride 2: 256 -> 128 -> 64 -> 32\n",
    "        self.flatten_size = 128 * 32 * 32\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(self.flatten_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()  # Sigmoid for binary classification\n",
    "        )\n",
    "        \n",
    "        # Define loss function and optimizer\n",
    "        self.criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch_size, 3, 256, 256)\n",
    "        x = self.conv_layers(x)\n",
    "        # Flatten the output\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # Pass through fully connected layers\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        # Forward pass\n",
    "        outputs = self.forward(images)\n",
    "        # Calculate loss\n",
    "        loss = self.criterion(outputs, labels.float().view(-1, 1))\n",
    "        # Backward pass\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        with torch.no_grad():\n",
    "            outputs = self(images)\n",
    "            loss = self.criterion(outputs, labels.float().view(-1, 1))\n",
    "            # Convert outputs to predictions (0 or 1)\n",
    "            predictions = (outputs >= 0.5).float() # TODO Put the threshold inside a variable\n",
    "            accuracy = (predictions == labels.view(-1, 1)).float().mean()\n",
    "        return loss.item(), accuracy.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training time\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train) \n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Initialize model, move to device\n",
    "device = torch.device(\"cpu\")\n",
    "model = CNN().to(device)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    print(f\"current epoch: {epoch}\")\n",
    "\n",
    "    # Progress bar for each epoch\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "    for batch_X, batch_y in progress_bar:\n",
    "        # Move batch to device\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        # Ensure input dimensions are correct (B, C, H, W)\n",
    "        if len(batch_X.shape) == 3:\n",
    "            batch_X = batch_X.unsqueeze(1)  # Add channel dimension if missing\n",
    "\n",
    "        # Forward pass\n",
    "        loss = model.training_step((batch_X, batch_y))\n",
    "\n",
    "        # Store batch loss\n",
    "        epoch_losses.append(loss)\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\"loss\": f\"{loss:.4f}\"})\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss = np.mean(epoch_losses)\n",
    "    train_losses.append(avg_loss)\n",
    "\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}:\")\n",
    "    print(f\"Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25204/3305388140.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model.load_state_dict(torch.load('./classifier.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layers): Sequential(\n",
       "    (0): Linear(in_features=131072, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (4): Sigmoid()\n",
       "  )\n",
       "  (criterion): BCELoss()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the model\n",
    "loaded_model = CNN()\n",
    "loaded_model.load_state_dict(torch.load('./classifier.pth'))\n",
    "\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9250, Accuracy: 0.5625\n",
      "Loss: 0.5962, Accuracy: 0.6875\n",
      "Loss: 1.1223, Accuracy: 0.5312\n",
      "Loss: 0.9725, Accuracy: 0.5625\n",
      "Loss: 0.6134, Accuracy: 0.7500\n",
      "Loss: 0.6586, Accuracy: 0.7188\n",
      "Loss: 0.7979, Accuracy: 0.7188\n",
      "Loss: 0.8763, Accuracy: 0.6562\n",
      "Loss: 0.7684, Accuracy: 0.7188\n",
      "Loss: 0.9153, Accuracy: 0.5625\n",
      "Loss: 0.6566, Accuracy: 0.7188\n",
      "Loss: 1.0371, Accuracy: 0.6250\n",
      "Loss: 0.9307, Accuracy: 0.6250\n",
      "Loss: 0.6305, Accuracy: 0.8438\n",
      "Loss: 0.9909, Accuracy: 0.5312\n",
      "Loss: 0.7922, Accuracy: 0.8333\n"
     ]
    }
   ],
   "source": [
    "# Validation time, TODO find ways to bump up the accuracy consistently in the 90s\n",
    "\n",
    "X_test_tensor = torch.FloatTensor(X_test) \n",
    "y_test_tensor = torch.FloatTensor(y_test)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "device = \"cpu\"\n",
    "for batch_X, batch_y in train_loader:\n",
    "    batch_X = batch_X.to(device)\n",
    "    batch_y = batch_y.to(device)\n",
    "    if len(batch_X.shape) == 3:\n",
    "        batch_X = batch_X.unsqueeze(1)\n",
    "    loss, accuracy = loaded_model.validation_step((batch_X, batch_y))\n",
    "    print(f\"Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
